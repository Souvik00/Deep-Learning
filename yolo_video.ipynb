{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics -q\n",
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "RqwjaNiHLMsE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance = {}"
      ],
      "metadata": {
        "id": "Sib0IKF8OuCZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '/content/v.mp4'\n"
      ],
      "metadata": {
        "id": "t8-jdL8qh64m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in [\"yolov8n\", \"yolo11n\", \"yolo12n\"]:\n",
        "    try:\n",
        "        model = YOLO(f\"{model_name}.pt\")\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video file {video_path}\")\n",
        "            continue\n",
        "\n",
        "        start_time = time.time()\n",
        "        frames_processed = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = model(frame, verbose=False)\n",
        "            frames_processed += 1\n",
        "\n",
        "        end_time = time.time()\n",
        "        cap.release()\n",
        "\n",
        "        inference_time = end_time - start_time\n",
        "        calculated_fps = frames_processed / inference_time if inference_time > 0 else 0\n",
        "\n",
        "        model_performance[model_name] = {\n",
        "            'inference_time_seconds': inference_time,\n",
        "            'processed_frames': frames_processed,\n",
        "            'calculated_fps': calculated_fps\n",
        "        }\n",
        "        print(f\"Finished processing with {model_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process with model {model_name}: {e}\")\n",
        "        model_performance[model_name] = {'error': str(e)}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GSz0bzgOuFX",
        "outputId": "ac3aab67-e554-4145-f8c1-8e3224e1f2e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished processing with yolov8n\n",
            "Finished processing with yolo11n\n",
            "Finished processing with yolo12n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Model Performance Comparison ---\")\n",
        "for model_name, metrics in model_performance.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    if 'error' in metrics:\n",
        "        print(f\"  Status: Error - {metrics['error']}\")\n",
        "    else:\n",
        "        print(f\"  Total Inference Time: {metrics['inference_time_seconds']:.2f} seconds\")\n",
        "        print(f\"  Frames Processed: {metrics['processed_frames']}\")\n",
        "        print(f\"  Calculated FPS: {metrics['calculated_fps']:.2f}\")\n",
        "        # Print other metrics here\n",
        "\n",
        "print(\"------------------------------------\")"
      ],
      "metadata": {
        "id": "G2CibNBbOuIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58996fd-f292-42a8-e6fa-04c512421528"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Performance Comparison ---\n",
            "\n",
            "Model: yolov8n\n",
            "  Total Inference Time: 114.43 seconds\n",
            "  Frames Processed: 598\n",
            "  Calculated FPS: 5.23\n",
            "\n",
            "Model: yolo11n\n",
            "  Total Inference Time: 98.98 seconds\n",
            "  Frames Processed: 598\n",
            "  Calculated FPS: 6.04\n",
            "\n",
            "Model: yolo12n\n",
            "  Total Inference Time: 101.36 seconds\n",
            "  Frames Processed: 598\n",
            "  Calculated FPS: 5.90\n",
            "------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}