{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.nn import utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getDataLoader(input_dir, batch_size, image_size, num_workers, labels_number):\n",
        "    dataset = MyCustomDataset(input_dir, csv_name, image_size, labels_number)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, drop_last=True\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyCustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_dir, csv_name, image_size, labels_number):\n",
        "        self.transform_to_apply = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "        ])\n",
        "        self.data_info = pd.read_csv(os.path.join(input_dir, csv_name))\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
        "        temp_labels = np.random.rand(self.image_arr.shape[0], len(labels_number))\n",
        "        for i in range(len(labels_number)):\n",
        "            temp_labels[0:-1,i] = (self.data_info.iloc[0:-1, labels_number[i]] )\n",
        "        self.label_arr = np.asarray(temp_labels)\n",
        "        self.data_len = len(self.data_info.index)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        single_image_name = self.image_arr[index]\n",
        "        img_as_img = Image.open(os.path.join(input_dir, single_image_name))\n",
        "        img = self.transform_to_apply(img_as_img)\n",
        "        single_image_label = self.label_arr[index]\n",
        "        for i in range(single_image_label.size):\n",
        "            if single_image_label[i] < 0:\n",
        "                single_image_label[i] = 0\n",
        "        return (img, single_image_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CategoricalConditionalBatchNorm(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_cats, eps=2e-5, momentum=0.1, affine=True,\n",
        "                 track_running_stats=True):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.num_cats = num_cats\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.affine = affine\n",
        "        self.track_running_stats = track_running_stats\n",
        "        if self.affine:\n",
        "            self.weight = torch.nn.Parameter(torch.Tensor(num_cats, num_features))\n",
        "            self.bias = torch.nn.Parameter(torch.Tensor(num_cats, num_features))\n",
        "        else:\n",
        "            self.register_parameter('weight', None)\n",
        "            self.register_parameter('bias', None)\n",
        "        if self.track_running_stats:\n",
        "            self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "            self.register_buffer('running_var', torch.ones(num_features))\n",
        "            self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
        "        else:\n",
        "            self.register_parameter('running_mean', None)\n",
        "            self.register_parameter('running_var', None)\n",
        "            self.register_parameter('num_batches_tracked', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_running_stats(self):\n",
        "        if self.track_running_stats:\n",
        "            self.running_mean.zero_()\n",
        "            self.running_var.fill_(1)\n",
        "            self.num_batches_tracked.zero_()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.reset_running_stats()\n",
        "        if self.affine:\n",
        "            self.weight.data.fill_(1.0)\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input, cats):\n",
        "        exponential_average_factor = 0.0\n",
        "        if self.training and self.track_running_stats:\n",
        "            self.num_batches_tracked += 1\n",
        "            if self.momentum is None:\n",
        "                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n",
        "            else:\n",
        "                exponential_average_factor = self.momentum\n",
        "        out = torch.nn.functional.batch_norm(\n",
        "            input, self.running_mean, self.running_var, None, None,\n",
        "            self.training or not self.track_running_stats,\n",
        "            exponential_average_factor, self.eps)\n",
        "        if self.affine:\n",
        "            shape = [input.size(0), self.num_features] + (input.dim() - 2) * [1]\n",
        "            weight = self.weight.index_select(0, cats).view(shape)\n",
        "            bias = self.bias.index_select(0, cats).view(shape)\n",
        "            out = out * weight + bias\n",
        "        return out\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return '{num_features}, num_cats={num_cats}, eps={eps}, momentum={momentum}, affine={affine}, ' \\\n",
        "               'track_running_stats={track_running_stats}'.format(**self.__dict__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, num_classes, d=128):\n",
        "        super(Generator, self).__init__()\n",
        "        self.deconv1_1 = nn.ConvTranspose2d(100, d*4, 4, 1, 0)\n",
        "        self.deconv1_1_bn = nn.BatchNorm2d(d*4)\n",
        "\n",
        "        self.deconv00_2 = nn.Conv2d(num_classes, int(d/4), 1, 1, 0)\n",
        "        self.deconv00_2_bn = nn.BatchNorm2d(int(d/4))\n",
        "        self.deconv0_2 = nn.ConvTranspose2d(int(d/4), d, 4, 1, 0)\n",
        "        self.deconv0_2_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv1_2 = nn.ConvTranspose2d(d, d*4, 3, 1, 1)\n",
        "        self.deconv1_2_bn = nn.BatchNorm2d(d*4)\n",
        "\n",
        "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "        self.deconv2_bn = CategoricalConditionalBatchNorm(d*4, num_classes)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "        self.deconv3_bn = CategoricalConditionalBatchNorm(d*2, num_classes)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
        "        self.deconv4_bn = CategoricalConditionalBatchNorm(d, num_classes)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d, 3, 4, 2, 1)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, input, label, cat):\n",
        "        x = F.leaky_relu(self.deconv1_1_bn(self.deconv1_1(input)), 0.2)\n",
        "\n",
        "        y = F.leaky_relu(self.deconv00_2_bn(self.deconv00_2(label)), 0.2)\n",
        "        y = F.leaky_relu(self.deconv0_2_bn(self.deconv0_2(y)), 0.2)\n",
        "        y = F.leaky_relu(self.deconv1_2_bn(self.deconv1_2(y)), 0.2)\n",
        "\n",
        "        x = torch.cat([x, y], 1)\n",
        "        x = F.leaky_relu(self.deconv2_bn(self.deconv2(x), cat), 0.2)\n",
        "        x = F.leaky_relu(self.deconv3_bn(self.deconv3(x), cat), 0.2)\n",
        "        x = F.leaky_relu(self.deconv4_bn(self.deconv4(x), cat), 0.2)\n",
        "        x = torch.tanh(self.deconv5(x))\n",
        "        return x\n",
        "\n",
        "# Discriminator (unchanged)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(3, int(d/2), 4, 2, 1)\n",
        "        self.conv0_2 = nn.Conv2d(2*n_labels, int(d/4), 1, 1, 0)\n",
        "        self.conv1_2 = nn.Conv2d(int(d/4), int(d/2), 4, 2, 1)\n",
        "\n",
        "        self.conv2 = utils.spectral_norm(nn.Conv2d(d, d*2, 4, 2, 1))\n",
        "        self.conv3 = utils.spectral_norm(nn.Conv2d(d*2, d*4, 4, 2, 1))\n",
        "        self.conv4 = utils.spectral_norm(nn.Conv2d(d*4, d*8, 4, 2, 1))\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        x = F.leaky_relu(self.conv1_1(input), 0.2)\n",
        "\n",
        "        y = F.leaky_relu(self.conv0_2(label), 0.2)\n",
        "        y = F.leaky_relu(self.conv1_2(y), 0.2)\n",
        "\n",
        "        x = torch.cat([x, y], 1)\n",
        "\n",
        "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv4(x), 0.2)\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getDiscriminatorLabels(lbl, batch_size, image_size):\n",
        "    if lbl.shape[1] == 1:\n",
        "        a = torch.zeros([batch_size, 2, image_size, image_size])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 1:\n",
        "                a[i,0,:,:] = 1\n",
        "            else:\n",
        "                a[i,1,:,:] = 1\n",
        "        return a\n",
        "    elif lbl.shape[1] == 2:\n",
        "        a = torch.zeros([batch_size, 4, image_size, image_size])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 1:\n",
        "                a[i,0,:,:] = 1\n",
        "            else:\n",
        "                a[i,1,:,:] = 1\n",
        "            if lbl[i][1] == 1:\n",
        "                a[i,2,:,:] = 1\n",
        "            else:\n",
        "                a[i,3,:,:] = 1\n",
        "        return a\n",
        "    else:\n",
        "        a = torch.zeros([batch_size, 6, image_size, image_size])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 1:\n",
        "                a[i,0,:,:] = 1\n",
        "            else:\n",
        "                a[i,1,:,:] = 1\n",
        "            if lbl[i][1] == 1:\n",
        "                a[i,2,:,:] = 1\n",
        "            else:\n",
        "                a[i,3,:,:] = 1\n",
        "            if lbl[i][2] == 1:\n",
        "                a[i,4,:,:] = 1\n",
        "            else:\n",
        "                a[i,5,:,:] = 1\n",
        "        return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getGeneratorLabels(lbl, batch_size):\n",
        "    if lbl.shape[1] == 1:\n",
        "        a = torch.zeros([batch_size, 2, 1, 1])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 1:\n",
        "                a[i,1,0,0] = 1\n",
        "            else:\n",
        "                a[i,0,0,0] = 1\n",
        "        return a\n",
        "    elif lbl.shape[1] == 2:\n",
        "        a = torch.zeros([batch_size, 4, 1, 1])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 1:\n",
        "                a[i,1,0,0] = 1\n",
        "            else:\n",
        "                a[i,0,0,0] = 1\n",
        "            if lbl[i][1] == 1:\n",
        "                a[i,3,0,0] = 1  # Fixed: was == (comparison) now = (assignment)\n",
        "            else:\n",
        "                a[i,2,0,0] = 1  # Fixed: was == (comparison) now = (assignment)\n",
        "        return a\n",
        "    else:\n",
        "        a = torch.zeros([batch_size, 6, 1, 1])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 1:\n",
        "                a[i,1,0,0] = 1\n",
        "            else:\n",
        "                a[i,0,0,0] = 1\n",
        "            if lbl[i][1] == 1:\n",
        "                a[i,3,0,0] = 1  # Fixed: was == (comparison) now = (assignment)\n",
        "            else:\n",
        "                a[i,2,0,0] = 1  # Fixed: was == (comparison) now = (assignment)\n",
        "            if lbl[i][2] == 1:\n",
        "                a[i,5,0,0] = 1\n",
        "            else:\n",
        "                a[i,4,0,0] = 1\n",
        "        return a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getGeneratorCategories(lbl, batch_size):\n",
        "    if lbl.shape[1] == 1:\n",
        "        a = torch.zeros([batch_size])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 1:\n",
        "                a[i] = 1\n",
        "            else:\n",
        "                a[i] = 0\n",
        "        return a.long()\n",
        "    elif lbl.shape[1] == 2:\n",
        "        a = torch.zeros([batch_size])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 0 and lbl[i][1] == 0:\n",
        "                a[i] = 0\n",
        "            elif lbl[i][0] == 0 and lbl[i][1] == 1:\n",
        "                a[i] = 1\n",
        "            elif lbl[i][0] == 1 and lbl[i][1] == 0:  # Fixed: was checking (0,1) again\n",
        "                a[i] = 2\n",
        "            else:  # (1,1)\n",
        "                a[i] = 3\n",
        "        return a.long()\n",
        "    else:\n",
        "        a = torch.zeros([batch_size])\n",
        "        for i in range(batch_size):\n",
        "            if lbl[i][0] == 0 and lbl[i][1] == 0 and lbl[i][2] == 0:\n",
        "                a[i] = 0\n",
        "            elif lbl[i][0] == 0 and lbl[i][1] == 0 and lbl[i][2] == 1:\n",
        "                a[i] = 1\n",
        "            elif lbl[i][0] == 0 and lbl[i][1] == 1 and lbl[i][2] == 0:\n",
        "                a[i] = 2\n",
        "            elif lbl[i][0] == 0 and lbl[i][1] == 1 and lbl[i][2] == 1:\n",
        "                a[i] = 3\n",
        "            elif lbl[i][0] == 1 and lbl[i][1] == 0 and lbl[i][2] == 0:\n",
        "                a[i] = 4\n",
        "            elif lbl[i][0] == 1 and lbl[i][1] == 0 and lbl[i][2] == 1:\n",
        "                a[i] = 5\n",
        "            elif lbl[i][0] == 1 and lbl[i][1] == 1 and lbl[i][2] == 0:\n",
        "                a[i] = 6\n",
        "            else:  # (1,1,1)\n",
        "                a[i] = 7\n",
        "        return a.long()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getGeneratorVisualizationLabels(n_features, batch_size):\n",
        "    remaining = batch_size - 64\n",
        "\n",
        "    if n_features == 1:\n",
        "        zeros = np.zeros((32,1))\n",
        "        ones = np.ones((32,1))\n",
        "        if remaining > 0:\n",
        "            lbl_tmp = np.concatenate((zeros,ones),axis=0)\n",
        "            remaining_zeros = np.zeros((remaining,1))\n",
        "            lbl = np.concatenate((lbl_tmp,remaining_zeros),axis = 0)\n",
        "        else:\n",
        "            lbl = np.concatenate((zeros,ones),axis=0)\n",
        "        return lbl\n",
        "    elif n_features == 2:\n",
        "        zeros = np.zeros((16,1))\n",
        "        ones = np.ones((16,1))\n",
        "        c1 = np.concatenate((zeros,ones,zeros,ones),axis =0)\n",
        "        c2 = np.concatenate((zeros,zeros,ones,ones),axis =0)\n",
        "        lbl = np.concatenate((c2,c1),axis=1)\n",
        "        if remaining > 0:\n",
        "            remaining_zeros = np.zeros((remaining,2))\n",
        "            lbl = np.concatenate((lbl,remaining_zeros),axis = 0)\n",
        "        return lbl\n",
        "    else:\n",
        "        zeros = np.zeros((8,1))\n",
        "        ones = np.ones((8,1))\n",
        "        c1 = np.concatenate((zeros,ones,zeros,ones,zeros,ones,zeros,ones),axis =0)\n",
        "        c2 = np.concatenate((zeros,zeros,ones,ones,zeros,zeros,ones,ones),axis =0)\n",
        "        c3 = np.concatenate((zeros,zeros,zeros,zeros,ones,ones,ones,ones),axis =0)\n",
        "        lbl = np.concatenate((c3,c2,c1),axis=1)\n",
        "        if remaining > 0:\n",
        "            remaining_zeros = np.zeros((remaining,3))\n",
        "            lbl = np.concatenate((lbl,remaining_zeros),axis = 0)\n",
        "        return lbl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "    print(\"Use device: \" + str(device))\n",
        "\n",
        "    # Fixed TensorBoard initialization\n",
        "    writer = SummaryWriter('/log')\n",
        "    visualization_name = 'CELEBA-GAN-1'\n",
        "\n",
        "    data_loader = getDataLoader(input_dir, batch_size, image_size, num_workers, labels_number)\n",
        "\n",
        "    # Save a sample of the training data\n",
        "    show_images = next(iter(data_loader))\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Training Images\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(show_images[0][0:64], padding=2, normalize=True),(1,2,0)))\n",
        "    plt.savefig(os.path.join(output_dir, 'training_sample.png'))\n",
        "    plt.close()  # Close to prevent display issues\n",
        "\n",
        "    netG = Generator(n_labels*2).to(device)\n",
        "    netD = Discriminator().to(device)\n",
        "\n",
        "    cost_fun = nn.BCELoss()\n",
        "    real_label = 1\n",
        "    fake_label = 0\n",
        "\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "    for current_epoch in range(num_epochs):\n",
        "        for batch_index, (data, lbl) in enumerate(data_loader, 0):\n",
        "            # Prepare real labels\n",
        "            lbl_real_disc = getDiscriminatorLabels(lbl, batch_size, image_size).to(device)\n",
        "\n",
        "            # Train Discriminator with real data\n",
        "            netD.zero_grad()\n",
        "            real_data = data.to(device)\n",
        "            b_size = real_data.size(0)\n",
        "            targets = torch.full((b_size,), real_label, device=device)\n",
        "            outputs = netD(real_data, lbl_real_disc).view(-1)\n",
        "            real_loss = cost_fun(outputs, targets)\n",
        "            real_loss.backward()\n",
        "            D_x = outputs.mean().item()\n",
        "\n",
        "            # Train Discriminator with fake data\n",
        "            fake_in_lbl_clear = np.random.randint(2, size=(batch_size, n_labels))\n",
        "            fake_in_lbl_g = getGeneratorLabels(fake_in_lbl_clear, batch_size).to(device)\n",
        "            fake_in_lbl_d = getDiscriminatorLabels(fake_in_lbl_clear, batch_size, image_size).to(device)\n",
        "            fake_cat = getGeneratorCategories(fake_in_lbl_clear, batch_size).to(device)\n",
        "\n",
        "            noise = torch.randn(b_size, g_input_dim, 1, 1, device=device)\n",
        "            fake = netG(noise, fake_in_lbl_g, fake_cat)\n",
        "\n",
        "            targets.fill_(fake_label)\n",
        "            output = netD(fake.detach(), fake_in_lbl_d).view(-1)\n",
        "            errD_fake = cost_fun(output, targets)\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            errD = real_loss + errD_fake\n",
        "            optimizerD.step()\n",
        "\n",
        "            # Train Generator\n",
        "            netG.zero_grad()\n",
        "            targets.fill_(real_label)\n",
        "            outputs = netD(fake, fake_in_lbl_d).view(-1)\n",
        "            loss_g = cost_fun(outputs, targets)\n",
        "            loss_g.backward()\n",
        "            D_G_z2 = outputs.mean().item()\n",
        "            optimizerG.step()\n",
        "\n",
        "            if batch_index % visualization_step == 0:\n",
        "                print(f'Epoch {current_epoch}/{num_epochs} batch {batch_index}/{len(data_loader)}')\n",
        "                print(f'Loss_D: {errD.item():.4f} Loss_G: {loss_g.item():.4f} D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
        "\n",
        "                # Generate visualization\n",
        "                fake_vis_label_clear = getGeneratorVisualizationLabels(n_labels, batch_size)\n",
        "                fake_vis_label = getGeneratorLabels(fake_vis_label_clear, batch_size).to(device)\n",
        "                fake_vis_cat = getGeneratorCategories(fake_vis_label_clear, batch_size).to(device)\n",
        "\n",
        "                noise_vis = torch.randn(b_size, g_input_dim, 1, 1, device=device)\n",
        "                visualFake = netG(noise_vis, fake_vis_label, fake_vis_cat)\n",
        "\n",
        "                # Save generated images\n",
        "                plt.figure(figsize=(8,8))\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(\"Generated Images\")\n",
        "                plt.imshow(np.transpose(vutils.make_grid(visualFake[0:64].detach().cpu(), padding=2, normalize=True),(1,2,0)))\n",
        "                plt.savefig(os.path.join(output_dir, f'result_{current_epoch}_{batch_index}.png'))\n",
        "                plt.close()  # Close to prevent display issues\n",
        "\n",
        "                # Log to TensorBoard\n",
        "                current_batch = current_epoch * len(data_loader) + batch_index\n",
        "                writer.add_scalar('Loss D real', D_x, current_batch)\n",
        "                writer.add_scalar('Loss D fake', D_G_z1, current_batch)\n",
        "                writer.add_scalar('Loss G', D_G_z2, current_batch)\n",
        "                writer.add_image('Generated Images', vutils.make_grid(visualFake[0:64], padding=2, normalize=True), current_batch)\n",
        "\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bx5Bp-UuR07",
        "outputId": "28b32df7-4931-445d-85a9-44eb8fbc947a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use device: cuda:0\n",
            "Using 10000 images for training\n",
            "Epoch 0/20 batch 0/156\n",
            "Loss_D: 1.3856 Loss_G: 0.8334 D(x): 0.5026 D(G(z)): 0.5022 / 0.4347\n",
            "Epoch 0/20 completed - Loss_D: 1.2980 Loss_G: 1.4629\n",
            "Epoch 1/20 completed - Loss_D: 1.1496 Loss_G: 1.1110\n",
            "Epoch 2/20 completed - Loss_D: 1.1483 Loss_G: 1.4135\n",
            "Epoch 3/20 completed - Loss_D: 0.9604 Loss_G: 1.2050\n",
            "Epoch 4/20 completed - Loss_D: 1.1447 Loss_G: 1.0184\n",
            "Epoch 5/20 batch 0/156\n",
            "Loss_D: 1.2798 Loss_G: 0.9846 D(x): 0.5728 D(G(z)): 0.4485 / 0.4001\n",
            "Epoch 5/20 completed - Loss_D: 1.2697 Loss_G: 1.0264\n",
            "Epoch 6/20 completed - Loss_D: 1.2887 Loss_G: 1.2332\n",
            "Epoch 7/20 completed - Loss_D: 1.2235 Loss_G: 1.0812\n",
            "Epoch 8/20 completed - Loss_D: 1.2094 Loss_G: 1.1190\n",
            "Epoch 9/20 completed - Loss_D: 1.2131 Loss_G: 1.2526\n",
            "Epoch 10/20 batch 0/156\n",
            "Loss_D: 1.0625 Loss_G: 1.4521 D(x): 0.6462 D(G(z)): 0.4072 / 0.2702\n",
            "Epoch 10/20 completed - Loss_D: 1.2443 Loss_G: 1.1922\n",
            "Epoch 11/20 completed - Loss_D: 1.1784 Loss_G: 1.0999\n",
            "Epoch 12/20 completed - Loss_D: 1.1700 Loss_G: 1.0497\n",
            "Epoch 13/20 completed - Loss_D: 1.2586 Loss_G: 1.1954\n",
            "Epoch 14/20 completed - Loss_D: 1.0647 Loss_G: 1.6832\n",
            "Epoch 15/20 batch 0/156\n",
            "Loss_D: 1.0540 Loss_G: 1.2362 D(x): 0.5226 D(G(z)): 0.2805 / 0.3132\n",
            "Epoch 15/20 completed - Loss_D: 0.9082 Loss_G: 1.6505\n",
            "Epoch 16/20 completed - Loss_D: 0.9226 Loss_G: 1.6440\n",
            "Epoch 17/20 completed - Loss_D: 0.9508 Loss_G: 1.7083\n",
            "Epoch 18/20 completed - Loss_D: 1.1083 Loss_G: 1.0689\n",
            "Epoch 19/20 completed - Loss_D: 0.9992 Loss_G: 1.4305\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 20\n",
        "input_dir = '/content/img_align_celeba/img_align_celeba'\n",
        "output_dir = '/content/generated'\n",
        "csv_name = '/content/list_attr_celeba.csv'\n",
        "num_workers = 2\n",
        "image_size = 64\n",
        "ngpu = 1\n",
        "g_input_dim = 100\n",
        "n_channels = 3\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "visualization_step = 200\n",
        "n_labels = 2\n",
        "labels_number = [32,9] \n",
        "ngf = 64\n",
        "ndf = 64\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
