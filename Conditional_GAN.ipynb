{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, label_dim, img_channels=3):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(label_dim, img_channels * img_size * img_size)\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(6, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 8 * 8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        label_embedding = self.label_emb(labels).view(labels.size(0), 3, img_size, img_size)\n",
        "        x = torch.cat([img, label_embedding], dim=1)\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, label_dim, img_channels=3):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(label_dim, z_dim)\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(z_dim * 2, 128 * 8 * 8),\n",
        "            nn.BatchNorm1d(128 * 8 * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.Unflatten(1, (128, 8, 8)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, img_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        label_embedding = self.label_emb(labels)\n",
        "        x = torch.cat([z, label_embedding], dim=1)\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov7zujC2tooM",
        "outputId": "bb11e780-3194-4cd0-d006-622f2eb3eab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20] | D Loss: 0.8003 | G Loss: 1.2384\n",
            "Epoch [2/20] | D Loss: 0.6971 | G Loss: 3.0782\n",
            "Epoch [3/20] | D Loss: 0.5445 | G Loss: 2.0417\n",
            "Epoch [4/20] | D Loss: 0.6199 | G Loss: 1.6738\n",
            "Epoch [5/20] | D Loss: 0.8204 | G Loss: 3.5382\n",
            "Epoch [6/20] | D Loss: 1.3846 | G Loss: 0.5518\n",
            "Epoch [7/20] | D Loss: 0.7650 | G Loss: 0.8919\n",
            "Epoch [8/20] | D Loss: 0.9777 | G Loss: 1.2962\n",
            "Epoch [9/20] | D Loss: 0.6779 | G Loss: 1.7242\n",
            "Epoch [10/20] | D Loss: 0.5818 | G Loss: 1.7265\n",
            "Epoch [11/20] | D Loss: 0.6770 | G Loss: 0.6224\n",
            "Epoch [12/20] | D Loss: 1.0123 | G Loss: 0.6182\n",
            "Epoch [13/20] | D Loss: 0.7717 | G Loss: 1.2984\n",
            "Epoch [14/20] | D Loss: 0.5891 | G Loss: 0.9734\n",
            "Epoch [15/20] | D Loss: 0.5045 | G Loss: 1.9183\n",
            "Epoch [16/20] | D Loss: 0.5665 | G Loss: 3.9800\n",
            "Epoch [17/20] | D Loss: 0.6862 | G Loss: 2.0207\n",
            "Epoch [18/20] | D Loss: 0.3417 | G Loss: 3.0633\n",
            "Epoch [19/20] | D Loss: 0.6892 | G Loss: 1.9215\n",
            "Epoch [20/20] | D Loss: 0.4587 | G Loss: 2.2163\n"
          ]
        }
      ],
      "source": [
        "\n",
        "z_dim = 100\n",
        "label_dim = 2\n",
        "batch_size = 64\n",
        "lr = 2e-4\n",
        "epochs = 20\n",
        "img_size = 64\n",
        "num_images = 10000\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(178),\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root='/content/celeba/img_align_celeba', transform=transform)\n",
        "subset = Subset(dataset, list(range(num_images)))\n",
        "dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "G = Generator(z_dim, label_dim).to(device)\n",
        "D = Discriminator(label_dim).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "os.makedirs(\"generated\", exist_ok=True)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for imgs, _ in dataloader:\n",
        "        batch_size = imgs.size(0)\n",
        "        real_imgs = imgs.to(device)\n",
        "        real_labels = torch.randint(0, label_dim, (batch_size,), device=device)\n",
        "\n",
        "        z = torch.randn(batch_size, z_dim).to(device)\n",
        "        fake_labels = torch.randint(0, label_dim, (batch_size,), device=device)\n",
        "        fake_imgs = G(z, fake_labels)\n",
        "\n",
        "        real_loss = criterion(D(real_imgs, real_labels), torch.ones(batch_size, 1).to(device))\n",
        "        fake_loss = criterion(D(fake_imgs.detach(), fake_labels), torch.zeros(batch_size, 1).to(device))\n",
        "        d_loss = real_loss + fake_loss\n",
        "\n",
        "        D.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        z = torch.randn(batch_size, z_dim).to(device)\n",
        "        gen_labels = torch.randint(0, label_dim, (batch_size,), device=device)\n",
        "        gen_imgs = G(z, gen_labels)\n",
        "        g_loss = criterion(D(gen_imgs, gen_labels), torch.ones(batch_size, 1).to(device))\n",
        "\n",
        "        G.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "    if epoch % 5 == 0:\n",
        "        G.eval()\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(16, z_dim).to(device)\n",
        "            sample_labels = torch.randint(0, label_dim, (16,), device=device)\n",
        "            fake_imgs = G(z, sample_labels)\n",
        "            fake_imgs = (fake_imgs + 1) / 2  # Denormalize\n",
        "            utils.save_image(fake_imgs, f\"generated/sample_epoch_{epoch}.png\", nrow=4)\n",
        "        G.train()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
